ggplot(Auto.train, aes(x = factor(cylinders), y = mpg)) +
geom_boxplot()
ggplot(Auto.train, aes(x = factor(year), y = mpg)) +
geom_boxplot()
ggplot(Auto.train, aes(x = factor(origin), y = mpg)) +
geom_boxplot()
plot1 <- ggplot(Auto.train, aes(x = factor(cylinders), y = mpg)) +
geom_boxplot()
plot2 <- ggplot(Auto.train, aes(x = factor(year), y = mpg)) +
geom_boxplot()
plot3 <- ggplot(Auto.train, aes(x = factor(origin), y = mpg)) +
geom_boxplot()
grid.arrange(plot1, plot2, plot3, nrow = 1)
plot(x=Auto$year, y=Auto$mpg01)
plot(x=Auto$origin, y=Auto$mpg01)
ggplot(Auto.train, aes(x=year, y=mpg))+
geom_point()
ggplot(Auto.train, aes(x = factor(year), y = mpg)) +
geom_boxplot()
ggplot(Auto.train, aes(x=origin, y=mpg))+
geom_point()
glm.fit <- glm(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train, family=binomial)
glm.probs <- predict(glm.fit, Auto.test, type="response")
glm.predict <- ifelse(glm.probs>0.5, 1, 0)
glm.error <- mean(glm.predict != Auto.test$mpg01)
lda.fit <- lda(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
lda.predict <- as.numeric(predict(lda.fit, Auto.test)$class)-1
lda.error <- mean(lda.predict != Auto.test$mpg01)
qda.fit <- qda(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
qda.predict <- as.numeric(predict(qda.fit, Auto.test)$class)-1
qda.error <- mean(qda.predict != Auto.test$mpg01)
nb.fit <- naiveBayes(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
nb.predict <- as.numeric(predict(nb.fit, Auto.test))-1
nb.error <- mean(nb.predict != Auto.test$mpg01)
c(glm.error, lda.error, qda.error, nb.error)
glm.fit <- glm(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train, family=binomial)
glm.probs <- predict(glm.fit, Auto.test, type="response")
glm.predict <- ifelse(glm.probs>0.5, 1, 0)
glm.error <- mean(glm.predict != Auto.test$mpg01)
lda.fit <- lda(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train)
lda.predict <- as.numeric(predict(lda.fit, Auto.test)$class)-1
lda.error <- mean(lda.predict != Auto.test$mpg01)
qda.fit <- qda(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train)
qda.predict <- as.numeric(predict(qda.fit, Auto.test)$class)-1
qda.error <- mean(qda.predict != Auto.test$mpg01)
nb.fit <- naiveBayes(mpg01 ~ displacement + horsepower + weight + acceleration + cylinders, data = Auto.train)
nb.predict <- as.numeric(predict(nb.fit, Auto.test))-1
nb.error <- mean(nb.predict != Auto.test$mpg01)
c(glm.error, lda.error, qda.error, nb.error)
<<fig=TRUE>>=
### LOGISTIC REGRESSION
glm.fit <- glm(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train, family=binomial)
glm.probs <- predict(glm.fit, Auto.test, type="response")
glm.predict <- ifelse(glm.probs>0.5, 1, 0)
glm.error <- mean(glm.predict != Auto.test$mpg01)
glm.tab <- table(Auto.test$mpg01, glm.predict)
glm.precision <- glm.tab[2,2]/(glm.tab[1,2]+glm.tab[2,2])
glm.recall <- glm.tab[2,2]/(glm.tab[2,1]+glm.tab[2,2])
glm.f1 <- 2*glm.precision* glm.recall/(glm.precision+ glm.recall)
### LDA
lda.fit <- lda(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
lda.predict <- as.numeric(predict(lda.fit, Auto.test)$class)-1
lda.error <- mean(lda.predict != Auto.test$mpg01)
lda.tab <- table(Auto.test$mpg01, lda.predict)
lda.precision <- lda.tab[2,2]/(lda.tab[1,2]+lda.tab[2,2])
lda.recall <- lda.tab[2,2]/(lda.tab[2,1]+lda.tab[2,2])
lda.f1 <- 2*lda.precision* lda.recall/(lda.precision+ lda.recall)
### QDA
qda.fit <- qda(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
qda.predict <- as.numeric(predict(qda.fit, Auto.test)$class)-1
qda.error <- mean(qda.predict != Auto.test$mpg01)
qda.tab <- table(Auto.test$mpg01, qda.predict)
qda.precision <- qda.tab[2,2]/(qda.tab[1,2]+qda.tab[2,2])
qda.recall <- qda.tab[2,2]/(qda.tab[2,1]+qda.tab[2,2])
qda.f1 <- 2*qda.precision*qda.recall/(qda.precision+qda.recall)
### NAIVE BAYES
nb.fit <- naiveBayes(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
nb.predict <- as.numeric(predict(nb.fit, Auto.test))-1
nb.error <- mean(nb.predict != Auto.test$mpg01)
nb.fit <- naiveBayes(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train)
nb.predict <- as.numeric(predict(nb.fit, Auto.test))-1
nb.error <- mean(nb.predict != Auto.test$mpg01)
nb.tab <- table(Auto.test$mpg01, nb.predict)
nb.precision <- nb.tab[2,2]/(nb.tab[1,2]+nb.tab[2,2])
nb.recall <- nb.tab[2,2]/(nb.tab[2,1]+nb.tab[2,2])
nb.f1 <- 2*nb.precision*nb.recall/(nb.precision+nb.recall)
### ROC CURVE
lda.probs <- predict(lda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
qda.probs <- predict(qda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
nb.probs <- predict(nb.fit, Auto.test, type = "raw")[,2]
glm.roc <- roc(Auto.test$mpg01, glm.probs)
lda.roc <- roc(Auto.test$mpg01, lda.probs)
qda.roc <- roc(Auto.test$mpg01, qda.probs)
nb.roc <- roc(Auto.test$mpg01, nb.probs)
plot(glm.roc, col="red")
lines(lda.roc, col="blue")
lines(qda.roc, col="green")
lines(nb.roc, col="purple")
### PRINT OUT RESULTS
cat ("MSE for glm, lda, qda, and Naive Bayes: ", glm.error, lda.error, qda.error, nb.error,"\n")
cat("F1-score for glm, lda, qda, and Naive Bayes: ", glm.f1, lda.f1, qda.f1, nb.f1)
cat("AUC for glm, lda, qda, and Naive Bayes: ", glm.roc$auc, lda.roc$auc, qda.roc$auc, nb.roc$auc)
par(mfrow = c(1,1))
glm.fit <- glm(mpg01 ~ displacement + horsepower + weight + acceleration + year, data = Auto.train, family=binomial)
glm.probs <- predict(glm.fit, Auto.test, type="response")
glm.predict <- ifelse(glm.probs>0.5, 1, 0)
glm.error <- mean(glm.predict != Auto.test$mpg01)
glm.tab <- table(Auto.test$mpg01, glm.predict)
glm.precision <- glm.tab[2,2]/(glm.tab[1,2]+glm.tab[2,2])
glm.recall <- glm.tab[2,2]/(glm.tab[2,1]+glm.tab[2,2])
glm.f1 <- 2*glm.precision* glm.recall/(glm.precision+ glm.recall)
### LDA
lda.fit <- lda(mpg01 ~ displacement + horsepower + weight + acceleration + year, data = Auto.train)
lda.predict <- as.numeric(predict(lda.fit, Auto.test)$class)-1
lda.error <- mean(lda.predict != Auto.test$mpg01)
lda.tab <- table(Auto.test$mpg01, lda.predict)
lda.precision <- lda.tab[2,2]/(lda.tab[1,2]+lda.tab[2,2])
lda.recall <- lda.tab[2,2]/(lda.tab[2,1]+lda.tab[2,2])
lda.f1 <- 2*lda.precision* lda.recall/(lda.precision+ lda.recall)
### QDA
qda.fit <- qda(mpg01 ~ displacement + horsepower + weight + acceleration + year, data = Auto.train)
qda.predict <- as.numeric(predict(qda.fit, Auto.test)$class)-1
qda.error <- mean(qda.predict != Auto.test$mpg01)
qda.tab <- table(Auto.test$mpg01, qda.predict)
qda.precision <- qda.tab[2,2]/(qda.tab[1,2]+qda.tab[2,2])
qda.recall <- qda.tab[2,2]/(qda.tab[2,1]+qda.tab[2,2])
qda.f1 <- 2*qda.precision*qda.recall/(qda.precision+qda.recall)
### NAIVE BAYES
nb.fit <- naiveBayes(mpg01 ~ displacement + horsepower + weight + acceleration + year, data = Auto.train)
nb.predict <- as.numeric(predict(nb.fit, Auto.test))-1
nb.error <- mean(nb.predict != Auto.test$mpg01)
nb.tab <- table(Auto.test$mpg01, nb.predict)
nb.precision <- nb.tab[2,2]/(nb.tab[1,2]+nb.tab[2,2])
nb.recall <- nb.tab[2,2]/(nb.tab[2,1]+nb.tab[2,2])
nb.f1 <- 2*nb.precision*nb.recall/(nb.precision+nb.recall)
### ROC CURVE
lda.probs <- predict(lda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
qda.probs <- predict(qda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
nb.probs <- predict(nb.fit, Auto.test, type = "raw")[,2]
glm.roc <- roc(Auto.test$mpg01, glm.probs)
lda.roc <- roc(Auto.test$mpg01, lda.probs)
qda.roc <- roc(Auto.test$mpg01, qda.probs)
nb.roc <- roc(Auto.test$mpg01, nb.probs)
plot(glm.roc, col="red")
lines(lda.roc, col="blue")
lines(qda.roc, col="green")
lines(nb.roc, col="purple")
### PRINT OUT RESULTS
cat("Test error for glm, lda, qda, and Naive Bayes: ", glm.error, lda.error, qda.error, nb.error,"\n")
cat("F1-score for glm, lda, qda, and Naive Bayes: ", glm.f1, lda.f1, qda.f1, nb.f1, "\n")
cat("AUC for glm, lda, qda, and Naive Bayes: ", glm.roc$auc, lda.roc$auc, qda.roc$auc, nb.roc$auc, "\n")
glm.fit <- glm(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train, family=binomial)
glm.probs <- predict(glm.fit, Auto.test, type="response")
glm.predict <- ifelse(glm.probs>0.5, 1, 0)
glm.error <- mean(glm.predict != Auto.test$mpg01)
glm.tab <- table(Auto.test$mpg01, glm.predict)
glm.precision <- glm.tab[2,2]/(glm.tab[1,2]+glm.tab[2,2])
glm.recall <- glm.tab[2,2]/(glm.tab[2,1]+glm.tab[2,2])
glm.f1 <- 2*glm.precision* glm.recall/(glm.precision+ glm.recall)
### LDA
lda.fit <- lda(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
lda.predict <- as.numeric(predict(lda.fit, Auto.test)$class)-1
lda.error <- mean(lda.predict != Auto.test$mpg01)
lda.tab <- table(Auto.test$mpg01, lda.predict)
lda.precision <- lda.tab[2,2]/(lda.tab[1,2]+lda.tab[2,2])
lda.recall <- lda.tab[2,2]/(lda.tab[2,1]+lda.tab[2,2])
lda.f1 <- 2*lda.precision* lda.recall/(lda.precision+ lda.recall)
### QDA
qda.fit <- qda(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
qda.predict <- as.numeric(predict(qda.fit, Auto.test)$class)-1
qda.error <- mean(qda.predict != Auto.test$mpg01)
qda.tab <- table(Auto.test$mpg01, qda.predict)
qda.precision <- qda.tab[2,2]/(qda.tab[1,2]+qda.tab[2,2])
qda.recall <- qda.tab[2,2]/(qda.tab[2,1]+qda.tab[2,2])
qda.f1 <- 2*qda.precision*qda.recall/(qda.precision+qda.recall)
### NAIVE BAYES
nb.fit <- naiveBayes(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
nb.predict <- as.numeric(predict(nb.fit, Auto.test))-1
nb.error <- mean(nb.predict != Auto.test$mpg01)
nb.tab <- table(Auto.test$mpg01, nb.predict)
nb.precision <- nb.tab[2,2]/(nb.tab[1,2]+nb.tab[2,2])
nb.recall <- nb.tab[2,2]/(nb.tab[2,1]+nb.tab[2,2])
nb.f1 <- 2*nb.precision*nb.recall/(nb.precision+nb.recall)
### ROC CURVE
lda.probs <- predict(lda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
qda.probs <- predict(qda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
nb.probs <- predict(nb.fit, Auto.test, type = "raw")[,2]
glm.roc <- roc(Auto.test$mpg01, glm.probs)
lda.roc <- roc(Auto.test$mpg01, lda.probs)
qda.roc <- roc(Auto.test$mpg01, qda.probs)
nb.roc <- roc(Auto.test$mpg01, nb.probs)
plot(glm.roc, col="red")
lines(lda.roc, col="blue")
lines(qda.roc, col="green")
lines(nb.roc, col="purple")
### PRINT OUT RESULTS
cat("Test error for glm, lda, qda, and Naive Bayes: ", glm.error, lda.error, qda.error, nb.error,"\n")
cat("F1-score for glm, lda, qda, and Naive Bayes: ", glm.f1, lda.f1, qda.f1, nb.f1, "\n")
cat("AUC for glm, lda, qda, and Naive Bayes: ", glm.roc$auc, lda.roc$auc, qda.roc$auc, nb.roc$auc, "\n")
plot1 <- ggplot(Auto, aes(x = factor(cylinders), y = mpg)) +
geom_boxplot()
plot2 <- ggplot(Auto, aes(x = factor(year), y = mpg)) +
geom_boxplot()
plot3 <- ggplot(Auto, aes(x = factor(origin), y = mpg)) +
geom_boxplot()
grid.arrange(plot1, plot2, plot3, nrow = 1)
set.seed(1)
idx.train <- sample(1:nrow(Auto), size=nrow(Auto)*.7)
idx.test <- setdiff(1:nrow(Auto), idx.train)
Auto.train <- Auto[idx.train,]
Auto.test <- Auto[idx.test,]
glm.fit <- glm(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train, family=binomial)
glm.probs <- predict(glm.fit, Auto.test, type="response")
glm.predict <- ifelse(glm.probs>0.5, 1, 0)
glm.error <- mean(glm.predict != Auto.test$mpg01)
glm.tab <- table(Auto.test$mpg01, glm.predict)
glm.precision <- glm.tab[2,2]/(glm.tab[1,2]+glm.tab[2,2])
glm.recall <- glm.tab[2,2]/(glm.tab[2,1]+glm.tab[2,2])
glm.f1 <- 2*glm.precision* glm.recall/(glm.precision+ glm.recall)
### LDA
lda.fit <- lda(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
lda.predict <- as.numeric(predict(lda.fit, Auto.test)$class)-1
lda.error <- mean(lda.predict != Auto.test$mpg01)
lda.tab <- table(Auto.test$mpg01, lda.predict)
lda.precision <- lda.tab[2,2]/(lda.tab[1,2]+lda.tab[2,2])
lda.recall <- lda.tab[2,2]/(lda.tab[2,1]+lda.tab[2,2])
lda.f1 <- 2*lda.precision* lda.recall/(lda.precision+ lda.recall)
### QDA
qda.fit <- qda(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
qda.predict <- as.numeric(predict(qda.fit, Auto.test)$class)-1
qda.error <- mean(qda.predict != Auto.test$mpg01)
qda.tab <- table(Auto.test$mpg01, qda.predict)
qda.precision <- qda.tab[2,2]/(qda.tab[1,2]+qda.tab[2,2])
qda.recall <- qda.tab[2,2]/(qda.tab[2,1]+qda.tab[2,2])
qda.f1 <- 2*qda.precision*qda.recall/(qda.precision+qda.recall)
### NAIVE BAYES
nb.fit <- naiveBayes(mpg01 ~ displacement + horsepower + weight + acceleration + year + origin, data = Auto.train)
nb.predict <- as.numeric(predict(nb.fit, Auto.test))-1
nb.error <- mean(nb.predict != Auto.test$mpg01)
nb.tab <- table(Auto.test$mpg01, nb.predict)
nb.precision <- nb.tab[2,2]/(nb.tab[1,2]+nb.tab[2,2])
nb.recall <- nb.tab[2,2]/(nb.tab[2,1]+nb.tab[2,2])
nb.f1 <- 2*nb.precision*nb.recall/(nb.precision+nb.recall)
### ROC CURVE
lda.probs <- predict(lda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
qda.probs <- predict(qda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
nb.probs <- predict(nb.fit, Auto.test, type = "raw")[,2]
glm.roc <- roc(Auto.test$mpg01, glm.probs)
lda.roc <- roc(Auto.test$mpg01, lda.probs)
qda.roc <- roc(Auto.test$mpg01, qda.probs)
nb.roc <- roc(Auto.test$mpg01, nb.probs)
plot(glm.roc, col="red")
lines(lda.roc, col="blue")
lines(qda.roc, col="green")
lines(nb.roc, col="purple")
cat("Test error for glm, lda, qda, and Naive Bayes: ", glm.error, lda.error, qda.error, nb.error,"\n")
cat("F1-score for glm, lda, qda, and Naive Bayes: ", glm.f1, lda.f1, qda.f1, nb.f1, "\n")
cat("AUC for glm, lda, qda, and Naive Bayes: ", glm.roc$auc, lda.roc$auc, qda.roc$auc, nb.roc$auc, "\n")
glm.fit <- glm(mpg01 ~ displacement + horsepower + weight + acceleration + year, data = Auto.train, family=binomial)
glm.probs <- predict(glm.fit, Auto.test, type="response")
glm.predict <- ifelse(glm.probs>0.5, 1, 0)
glm.error <- mean(glm.predict != Auto.test$mpg01)
glm.tab <- table(Auto.test$mpg01, glm.predict)
glm.precision <- glm.tab[2,2]/(glm.tab[1,2]+glm.tab[2,2])
glm.recall <- glm.tab[2,2]/(glm.tab[2,1]+glm.tab[2,2])
glm.f1 <- 2*glm.precision* glm.recall/(glm.precision+ glm.recall)
### LDA
lda.fit <- lda(mpg01 ~ displacement + horsepower + weight + acceleration + year, data = Auto.train)
lda.predict <- as.numeric(predict(lda.fit, Auto.test)$class)-1
lda.error <- mean(lda.predict != Auto.test$mpg01)
lda.tab <- table(Auto.test$mpg01, lda.predict)
lda.precision <- lda.tab[2,2]/(lda.tab[1,2]+lda.tab[2,2])
lda.recall <- lda.tab[2,2]/(lda.tab[2,1]+lda.tab[2,2])
lda.f1 <- 2*lda.precision* lda.recall/(lda.precision+ lda.recall)
### QDA
qda.fit <- qda(mpg01 ~ displacement + horsepower + weight + acceleration + year, data = Auto.train)
qda.predict <- as.numeric(predict(qda.fit, Auto.test)$class)-1
qda.error <- mean(qda.predict != Auto.test$mpg01)
qda.tab <- table(Auto.test$mpg01, qda.predict)
qda.precision <- qda.tab[2,2]/(qda.tab[1,2]+qda.tab[2,2])
qda.recall <- qda.tab[2,2]/(qda.tab[2,1]+qda.tab[2,2])
qda.f1 <- 2*qda.precision*qda.recall/(qda.precision+qda.recall)
### NAIVE BAYES
nb.fit <- naiveBayes(mpg01 ~ displacement + horsepower + weight + acceleration + year, data = Auto.train)
nb.predict <- as.numeric(predict(nb.fit, Auto.test))-1
nb.error <- mean(nb.predict != Auto.test$mpg01)
nb.tab <- table(Auto.test$mpg01, nb.predict)
nb.precision <- nb.tab[2,2]/(nb.tab[1,2]+nb.tab[2,2])
nb.recall <- nb.tab[2,2]/(nb.tab[2,1]+nb.tab[2,2])
nb.f1 <- 2*nb.precision*nb.recall/(nb.precision+nb.recall)
### ROC CURVE
lda.probs <- predict(lda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
qda.probs <- predict(qda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
nb.probs <- predict(nb.fit, Auto.test, type = "raw")[,2]
glm.roc <- roc(Auto.test$mpg01, glm.probs)
lda.roc <- roc(Auto.test$mpg01, lda.probs)
qda.roc <- roc(Auto.test$mpg01, qda.probs)
nb.roc <- roc(Auto.test$mpg01, nb.probs)
plot(glm.roc, col="red")
lines(lda.roc, col="blue")
lines(qda.roc, col="green")
lines(nb.roc, col="purple")
### PRINT OUT RESULTS
cat("Test error for glm, lda, qda, and Naive Bayes: ", glm.error, lda.error, qda.error, nb.error,"\n")
cat("F1-score for glm, lda, qda, and Naive Bayes: ", glm.f1, lda.f1, qda.f1, nb.f1, "\n")
cat("AUC for glm, lda, qda, and Naive Bayes: ", glm.roc$auc, lda.roc$auc, qda.roc$auc, nb.roc$auc, "\n")
glm.fit <- glm(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train, family=binomial)
glm.probs <- predict(glm.fit, Auto.test, type="response")
glm.predict <- ifelse(glm.probs>0.5, 1, 0)
glm.error <- mean(glm.predict != Auto.test$mpg01)
glm.tab <- table(Auto.test$mpg01, glm.predict)
glm.precision <- glm.tab[2,2]/(glm.tab[1,2]+glm.tab[2,2])
glm.recall <- glm.tab[2,2]/(glm.tab[2,1]+glm.tab[2,2])
glm.f1 <- 2*glm.precision* glm.recall/(glm.precision+ glm.recall)
### LDA
lda.fit <- lda(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train)
lda.predict <- as.numeric(predict(lda.fit, Auto.test)$class)-1
lda.error <- mean(lda.predict != Auto.test$mpg01)
lda.tab <- table(Auto.test$mpg01, lda.predict)
lda.precision <- lda.tab[2,2]/(lda.tab[1,2]+lda.tab[2,2])
lda.recall <- lda.tab[2,2]/(lda.tab[2,1]+lda.tab[2,2])
lda.f1 <- 2*lda.precision* lda.recall/(lda.precision+ lda.recall)
### QDA
qda.fit <- qda(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train)
qda.predict <- as.numeric(predict(qda.fit, Auto.test)$class)-1
qda.error <- mean(qda.predict != Auto.test$mpg01)
qda.tab <- table(Auto.test$mpg01, qda.predict)
qda.precision <- qda.tab[2,2]/(qda.tab[1,2]+qda.tab[2,2])
qda.recall <- qda.tab[2,2]/(qda.tab[2,1]+qda.tab[2,2])
qda.f1 <- 2*qda.precision*qda.recall/(qda.precision+qda.recall)
### NAIVE BAYES
nb.fit <- naiveBayes(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train)
nb.predict <- as.numeric(predict(nb.fit, Auto.test))-1
nb.error <- mean(nb.predict != Auto.test$mpg01)
nb.tab <- table(Auto.test$mpg01, nb.predict)
nb.precision <- nb.tab[2,2]/(nb.tab[1,2]+nb.tab[2,2])
nb.recall <- nb.tab[2,2]/(nb.tab[2,1]+nb.tab[2,2])
nb.f1 <- 2*nb.precision*nb.recall/(nb.precision+nb.recall)
### ROC CURVE
lda.probs <- predict(lda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
qda.probs <- predict(qda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
nb.probs <- predict(nb.fit, Auto.test, type = "raw")[,2]
glm.roc <- roc(Auto.test$mpg01, glm.probs)
lda.roc <- roc(Auto.test$mpg01, lda.probs)
qda.roc <- roc(Auto.test$mpg01, qda.probs)
nb.roc <- roc(Auto.test$mpg01, nb.probs)
plot(glm.roc, col="red")
lines(lda.roc, col="blue")
lines(qda.roc, col="green")
lines(nb.roc, col="purple")
### PRINT OUT RESULTS
cat("Test error for glm, lda, qda, and Naive Bayes: ", glm.error, lda.error, qda.error, nb.error,"\n")
cat("F1-score for glm, lda, qda, and Naive Bayes: ", glm.f1, lda.f1, qda.f1, nb.f1, "\n")
cat("AUC for glm, lda, qda, and Naive Bayes: ", glm.roc$auc, lda.roc$auc, qda.roc$auc, nb.roc$auc, "\n")
set.seed(1)
idx.train <- sample(1:nrow(Auto), size=nrow(Auto)*.7)
idx.test <- setdiff(1:nrow(Auto), idx.train)
Auto.train <- Auto[idx.train,]
Auto.test <- Auto[idx.test,]
<<fig=TRUE>>=
### LOGISTIC REGRESSION
glm.fit <- glm(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train, family=binomial)
glm.probs <- predict(glm.fit, Auto.test, type="response")
glm.predict <- ifelse(glm.probs>0.5, 1, 0)
glm.error <- mean(glm.predict != Auto.test$mpg01)
glm.tab <- table(Auto.test$mpg01, glm.predict)
glm.precision <- glm.tab[2,2]/(glm.tab[1,2]+glm.tab[2,2])
glm.recall <- glm.tab[2,2]/(glm.tab[2,1]+glm.tab[2,2])
glm.f1 <- 2*glm.precision* glm.recall/(glm.precision+ glm.recall)
### LDA
lda.fit <- lda(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train)
lda.predict <- as.numeric(predict(lda.fit, Auto.test)$class)-1
lda.error <- mean(lda.predict != Auto.test$mpg01)
lda.tab <- table(Auto.test$mpg01, lda.predict)
lda.precision <- lda.tab[2,2]/(lda.tab[1,2]+lda.tab[2,2])
lda.recall <- lda.tab[2,2]/(lda.tab[2,1]+lda.tab[2,2])
lda.f1 <- 2*lda.precision* lda.recall/(lda.precision+ lda.recall)
### QDA
qda.fit <- qda(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train)
qda.predict <- as.numeric(predict(qda.fit, Auto.test)$class)-1
qda.error <- mean(qda.predict != Auto.test$mpg01)
qda.tab <- table(Auto.test$mpg01, qda.predict)
qda.precision <- qda.tab[2,2]/(qda.tab[1,2]+qda.tab[2,2])
qda.recall <- qda.tab[2,2]/(qda.tab[2,1]+qda.tab[2,2])
qda.f1 <- 2*qda.precision*qda.recall/(qda.precision+qda.recall)
### NAIVE BAYES
nb.fit <- naiveBayes(mpg01 ~ displacement + horsepower + weight + acceleration, data = Auto.train)
nb.predict <- as.numeric(predict(nb.fit, Auto.test))-1
nb.error <- mean(nb.predict != Auto.test$mpg01)
nb.tab <- table(Auto.test$mpg01, nb.predict)
nb.precision <- nb.tab[2,2]/(nb.tab[1,2]+nb.tab[2,2])
nb.recall <- nb.tab[2,2]/(nb.tab[2,1]+nb.tab[2,2])
nb.f1 <- 2*nb.precision*nb.recall/(nb.precision+nb.recall)
### ROC CURVE
lda.probs <- predict(lda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
qda.probs <- predict(qda.fit, Auto.test)$posterior[,2] # Probabilities for class 1
nb.probs <- predict(nb.fit, Auto.test, type = "raw")[,2]
glm.roc <- roc(Auto.test$mpg01, glm.probs)
lda.roc <- roc(Auto.test$mpg01, lda.probs)
qda.roc <- roc(Auto.test$mpg01, qda.probs)
nb.roc <- roc(Auto.test$mpg01, nb.probs)
plot(glm.roc, col="red")
lines(lda.roc, col="blue")
lines(qda.roc, col="green")
lines(nb.roc, col="purple")
### PRINT OUT RESULTS
cat("Test error for glm, lda, qda, and Naive Bayes: ", glm.error, lda.error, qda.error, nb.error,"\n")
cat("F1-score for glm, lda, qda, and Naive Bayes: ", glm.f1, lda.f1, qda.f1, nb.f1, "\n")
cat("AUC for glm, lda, qda, and Naive Bayes: ", glm.roc$auc, lda.roc$auc, qda.roc$auc, nb.roc$auc, "\n")
plot1 <- ggplot(Auto, aes(x = factor(cylinders), y = mpg01)) +
geom_boxplot()
plot2 <- ggplot(Auto, aes(x = factor(year), y = mpg01)) +
geom_boxplot()
plot3 <- ggplot(Auto, aes(x = factor(origin), y = mpg01)) +
geom_boxplot()
grid.arrange(plot1, plot2, plot3, nrow = 1)
data <- data.frame(
X1 = c(3, 2, 4, 1, 2, 4, 4),
X2 = c(4, 2, 4, 4, 1, 3, 1),
Y = as.factor(c('Red', 'Red', 'Red', 'Red', 'Blue', 'Blue', 'Blue'))
)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point(size=3)
data <- data.frame(
X1 = c(3, 2, 4, 1, 2, 4, 4),
X2 = c(4, 2, 4, 4, 1, 3, 1),
Y = c('Red', 'Red', 'Red', 'Red', 'Blue', 'Blue', 'Blue')
)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()
model <- svm(Y ~ ., data=data, type='C-classification', kernel='linear', cost=1e5, scale=FALSE)
model
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
geom_abline(slope=1, intercept=1/2)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
geom_abline(slope=1, intercept=-1/2)
data
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()
ggplot(data, aes(x=X1, y=X2, color=factor(Y))) +
geom_point()
data <- data.frame(
X1 = c(3, 2, 4, 1, 2, 4, 4),
X2 = c(4, 2, 4, 4, 1, 3, 1),
Y = factor(c('Red', 'Red', 'Red', 'Red', 'Blue', 'Blue', 'Blue')))
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue" ))
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_abline(slope=1, intercept=-1/2)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_abline(slope=1, intercept=-1/2)+
geom_abline(slope=1, intercept=1/2)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_abline(slope=1, intercept=-1/2)+
geom_abline(slope=1, intercept=-1/4)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_abline(slope=1, intercept=-1/2)+
geom_abline(slope=1, intercept=-1/3)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_abline(slope=1, intercept=-1/2)+
geom_abline(slope=1, intercept=0)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_abline(slope=1, intercept=-1/2)+
geom_abline(slope=1, intercept=0, linetype=dashed)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_abline(slope=1, intercept=-1/2)+
geom_abline(slope=1, intercept=0, linetype=2)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_abline(slope=1, intercept=-1/2)+
geom_abline(slope=1, intercept=0, linetype=2)+
geom_abline(slope=1, intercept=-1, linetype=2)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_abline(slope=1, intercept=-1/2)+
geom_abline(slope=1, intercept=-1/3)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_abline(slope=1, intercept=-1/2)+
geom_abline(slope=1, intercept=-1/3, linetype=2)
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))
new.obs <- data.frame(X1=1.5,X2=2.5,Y="Blue")
ggplot(data, aes(x=X1, y=X2, color=Y)) +
geom_point()+
scale_color_manual(values=c('Red'="red", 'Blue'="blue"))+
geom_point(data=new.obs, aes(x=X1, y=X2))
getwd()
setwd('D:/Projects/breast_cancer_pred')
